{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report\n\nfrom keras import Sequential,losses\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-05T15:57:07.202349Z","iopub.execute_input":"2023-08-05T15:57:07.204921Z","iopub.status.idle":"2023-08-05T15:57:07.229896Z","shell.execute_reply.started":"2023-08-05T15:57:07.204883Z","shell.execute_reply":"2023-08-05T15:57:07.228656Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv\n/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data/A_Z Handwritten Data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:57:07.234186Z","iopub.execute_input":"2023-08-05T15:57:07.235665Z","iopub.status.idle":"2023-08-05T15:57:33.746456Z","shell.execute_reply.started":"2023-08-05T15:57:07.235630Z","shell.execute_reply":"2023-08-05T15:57:33.745235Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T15:57:33.747917Z","iopub.execute_input":"2023-08-05T15:57:33.748968Z","iopub.status.idle":"2023-08-05T15:57:38.891554Z","shell.execute_reply.started":"2023-08-05T15:57:33.748928Z","shell.execute_reply":"2023-08-05T15:57:38.890446Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(width_shift_range=2,height_shift_range=2,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:01:07.378337Z","iopub.execute_input":"2023-08-05T16:01:07.378746Z","iopub.status.idle":"2023-08-05T16:01:07.384524Z","shell.execute_reply.started":"2023-08-05T16:01:07.378715Z","shell.execute_reply":"2023-08-05T16:01:07.383206Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X = df.loc[:,\"0.1\":]\ny = df.loc[:,\"0\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:01:09.539801Z","iopub.execute_input":"2023-08-05T16:01:09.540176Z","iopub.status.idle":"2023-08-05T16:01:09.545231Z","shell.execute_reply.started":"2023-08-05T16:01:09.540148Z","shell.execute_reply":"2023-08-05T16:01:09.544192Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X=X.values.reshape(len(X),28,28,1)\nX_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.85)\nX_train = X_train/255\nX_test = X_test/255\ny_train=np_utils.to_categorical(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:01:46.440952Z","iopub.execute_input":"2023-08-05T16:01:46.441356Z","iopub.status.idle":"2023-08-05T16:01:51.674771Z","shell.execute_reply.started":"2023-08-05T16:01:46.441324Z","shell.execute_reply":"2023-08-05T16:01:51.673585Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv2D(16,(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(strides=(1,1)))\nmodel.add(Conv2D(8,(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(strides=(1,1)))\nmodel.add(Conv2D(8,(3,3),activation=\"relu\"))\nmodel.add(MaxPooling2D(strides=(1,1)))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dense(64,activation=\"relu\"))\nmodel.add(Dense(26,activation=\"softmax\"))\nmodel.compile(loss=losses.categorical_crossentropy,metrics=[\"accuracy\"],optimizer=SGD(learning_rate=0.05))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:01:58.275455Z","iopub.execute_input":"2023-08-05T16:01:58.275827Z","iopub.status.idle":"2023-08-05T16:01:58.307775Z","shell.execute_reply.started":"2023-08-05T16:01:58.275796Z","shell.execute_reply":"2023-08-05T16:01:58.306863Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(filepath=\"model_sgd.pkl\",monitor=\"val_accuracy\",verbose=2,save_best_only=True,mode=\"max\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:02:01.759349Z","iopub.execute_input":"2023-08-05T16:02:01.760304Z","iopub.status.idle":"2023-08-05T16:02:01.766279Z","shell.execute_reply.started":"2023-08-05T16:02:01.760251Z","shell.execute_reply":"2023-08-05T16:02:01.764892Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.fit(datagen.flow(X_train, y_train, batch_size=128,subset=\"training\"),\n          validation_data=datagen.flow(X_train, y_train, batch_size=128,subset=\"validation\"),\n          epochs=50,batch_size=128,verbose=2,callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:02:03.926029Z","iopub.execute_input":"2023-08-05T16:02:03.926380Z","iopub.status.idle":"2023-08-05T16:47:52.652064Z","shell.execute_reply.started":"2023-08-05T16:02:03.926350Z","shell.execute_reply":"2023-08-05T16:47:52.650976Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\nEpoch 1: val_accuracy improved from -inf to 0.95320, saving model to model_sgd.pkl\n1069/1069 - 54s - loss: 0.5879 - accuracy: 0.8325 - val_loss: 0.1641 - val_accuracy: 0.9532 - 54s/epoch - 50ms/step\nEpoch 2/50\n\nEpoch 2: val_accuracy improved from 0.95320 to 0.96958, saving model to model_sgd.pkl\n1069/1069 - 52s - loss: 0.1377 - accuracy: 0.9608 - val_loss: 0.1105 - val_accuracy: 0.9696 - 52s/epoch - 49ms/step\nEpoch 3/50\n\nEpoch 3: val_accuracy improved from 0.96958 to 0.97221, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.1026 - accuracy: 0.9708 - val_loss: 0.0967 - val_accuracy: 0.9722 - 53s/epoch - 49ms/step\nEpoch 4/50\n\nEpoch 4: val_accuracy improved from 0.97221 to 0.97686, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0883 - accuracy: 0.9752 - val_loss: 0.0826 - val_accuracy: 0.9769 - 53s/epoch - 50ms/step\nEpoch 5/50\n\nEpoch 5: val_accuracy improved from 0.97686 to 0.97774, saving model to model_sgd.pkl\n1069/1069 - 52s - loss: 0.0769 - accuracy: 0.9784 - val_loss: 0.0787 - val_accuracy: 0.9777 - 52s/epoch - 49ms/step\nEpoch 6/50\n\nEpoch 6: val_accuracy improved from 0.97774 to 0.97800, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0701 - accuracy: 0.9801 - val_loss: 0.0781 - val_accuracy: 0.9780 - 53s/epoch - 50ms/step\nEpoch 7/50\n\nEpoch 7: val_accuracy did not improve from 0.97800\n1069/1069 - 52s - loss: 0.0651 - accuracy: 0.9815 - val_loss: 0.0860 - val_accuracy: 0.9761 - 52s/epoch - 49ms/step\nEpoch 8/50\n\nEpoch 8: val_accuracy improved from 0.97800 to 0.97809, saving model to model_sgd.pkl\n1069/1069 - 52s - loss: 0.0602 - accuracy: 0.9829 - val_loss: 0.0787 - val_accuracy: 0.9781 - 52s/epoch - 49ms/step\nEpoch 9/50\n\nEpoch 9: val_accuracy improved from 0.97809 to 0.97938, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0564 - accuracy: 0.9837 - val_loss: 0.0745 - val_accuracy: 0.9794 - 53s/epoch - 50ms/step\nEpoch 10/50\n\nEpoch 10: val_accuracy improved from 0.97938 to 0.98084, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0539 - accuracy: 0.9845 - val_loss: 0.0687 - val_accuracy: 0.9808 - 53s/epoch - 49ms/step\nEpoch 11/50\n\nEpoch 11: val_accuracy improved from 0.98084 to 0.98134, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0520 - accuracy: 0.9852 - val_loss: 0.0671 - val_accuracy: 0.9813 - 53s/epoch - 49ms/step\nEpoch 12/50\n\nEpoch 12: val_accuracy did not improve from 0.98134\n1069/1069 - 52s - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.0713 - val_accuracy: 0.9800 - 52s/epoch - 49ms/step\nEpoch 13/50\n\nEpoch 13: val_accuracy improved from 0.98134 to 0.98295, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0461 - accuracy: 0.9864 - val_loss: 0.0608 - val_accuracy: 0.9829 - 53s/epoch - 50ms/step\nEpoch 14/50\n\nEpoch 14: val_accuracy did not improve from 0.98295\n1069/1069 - 52s - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.0645 - val_accuracy: 0.9823 - 52s/epoch - 49ms/step\nEpoch 15/50\n\nEpoch 15: val_accuracy did not improve from 0.98295\n1069/1069 - 52s - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.0667 - val_accuracy: 0.9812 - 52s/epoch - 49ms/step\nEpoch 16/50\n\nEpoch 16: val_accuracy did not improve from 0.98295\n1069/1069 - 51s - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.0688 - val_accuracy: 0.9817 - 51s/epoch - 48ms/step\nEpoch 17/50\n\nEpoch 17: val_accuracy did not improve from 0.98295\n1069/1069 - 52s - loss: 0.0387 - accuracy: 0.9884 - val_loss: 0.0676 - val_accuracy: 0.9827 - 52s/epoch - 48ms/step\nEpoch 18/50\n\nEpoch 18: val_accuracy did not improve from 0.98295\n1069/1069 - 52s - loss: 0.0375 - accuracy: 0.9889 - val_loss: 0.0625 - val_accuracy: 0.9829 - 52s/epoch - 49ms/step\nEpoch 19/50\n\nEpoch 19: val_accuracy improved from 0.98295 to 0.98365, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0365 - accuracy: 0.9887 - val_loss: 0.0618 - val_accuracy: 0.9836 - 53s/epoch - 49ms/step\nEpoch 20/50\n\nEpoch 20: val_accuracy did not improve from 0.98365\n1069/1069 - 52s - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.0609 - val_accuracy: 0.9829 - 52s/epoch - 49ms/step\nEpoch 21/50\n\nEpoch 21: val_accuracy did not improve from 0.98365\n1069/1069 - 52s - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.0611 - val_accuracy: 0.9832 - 52s/epoch - 48ms/step\nEpoch 22/50\n\nEpoch 22: val_accuracy improved from 0.98365 to 0.98388, saving model to model_sgd.pkl\n1069/1069 - 52s - loss: 0.0329 - accuracy: 0.9898 - val_loss: 0.0620 - val_accuracy: 0.9839 - 52s/epoch - 49ms/step\nEpoch 23/50\n\nEpoch 23: val_accuracy did not improve from 0.98388\n1069/1069 - 51s - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0680 - val_accuracy: 0.9820 - 51s/epoch - 48ms/step\nEpoch 24/50\n\nEpoch 24: val_accuracy improved from 0.98388 to 0.98415, saving model to model_sgd.pkl\n1069/1069 - 51s - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0609 - val_accuracy: 0.9841 - 51s/epoch - 48ms/step\nEpoch 25/50\n\nEpoch 25: val_accuracy did not improve from 0.98415\n1069/1069 - 50s - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0712 - val_accuracy: 0.9813 - 50s/epoch - 47ms/step\nEpoch 26/50\n\nEpoch 26: val_accuracy did not improve from 0.98415\n1069/1069 - 50s - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0654 - val_accuracy: 0.9832 - 50s/epoch - 47ms/step\nEpoch 27/50\n\nEpoch 27: val_accuracy did not improve from 0.98415\n1069/1069 - 50s - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.0668 - val_accuracy: 0.9827 - 50s/epoch - 47ms/step\nEpoch 28/50\n\nEpoch 28: val_accuracy improved from 0.98415 to 0.98435, saving model to model_sgd.pkl\n1069/1069 - 52s - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0607 - val_accuracy: 0.9844 - 52s/epoch - 48ms/step\nEpoch 29/50\n\nEpoch 29: val_accuracy did not improve from 0.98435\n1069/1069 - 50s - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0680 - val_accuracy: 0.9828 - 50s/epoch - 47ms/step\nEpoch 30/50\n\nEpoch 30: val_accuracy did not improve from 0.98435\n1069/1069 - 50s - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.0636 - val_accuracy: 0.9840 - 50s/epoch - 47ms/step\nEpoch 31/50\n\nEpoch 31: val_accuracy did not improve from 0.98435\n1069/1069 - 51s - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0636 - val_accuracy: 0.9840 - 51s/epoch - 47ms/step\nEpoch 32/50\n\nEpoch 32: val_accuracy did not improve from 0.98435\n1069/1069 - 50s - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.0603 - val_accuracy: 0.9844 - 50s/epoch - 47ms/step\nEpoch 33/50\n\nEpoch 33: val_accuracy did not improve from 0.98435\n1069/1069 - 52s - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0655 - val_accuracy: 0.9836 - 52s/epoch - 49ms/step\nEpoch 34/50\n\nEpoch 34: val_accuracy did not improve from 0.98435\n1069/1069 - 52s - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0675 - val_accuracy: 0.9836 - 52s/epoch - 49ms/step\nEpoch 35/50\n\nEpoch 35: val_accuracy did not improve from 0.98435\n1069/1069 - 52s - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0672 - val_accuracy: 0.9839 - 52s/epoch - 49ms/step\nEpoch 36/50\n\nEpoch 36: val_accuracy did not improve from 0.98435\n1069/1069 - 52s - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0646 - val_accuracy: 0.9838 - 52s/epoch - 49ms/step\nEpoch 37/50\n\nEpoch 37: val_accuracy did not improve from 0.98435\n1069/1069 - 51s - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0702 - val_accuracy: 0.9822 - 51s/epoch - 48ms/step\nEpoch 38/50\n\nEpoch 38: val_accuracy improved from 0.98435 to 0.98494, saving model to model_sgd.pkl\n1069/1069 - 53s - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0623 - val_accuracy: 0.9849 - 53s/epoch - 50ms/step\nEpoch 39/50\n\nEpoch 39: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0693 - val_accuracy: 0.9829 - 52s/epoch - 48ms/step\nEpoch 40/50\n\nEpoch 40: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0694 - val_accuracy: 0.9832 - 52s/epoch - 48ms/step\nEpoch 41/50\n\nEpoch 41: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0612 - val_accuracy: 0.9848 - 52s/epoch - 49ms/step\nEpoch 42/50\n\nEpoch 42: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0652 - val_accuracy: 0.9845 - 52s/epoch - 49ms/step\nEpoch 43/50\n\nEpoch 43: val_accuracy did not improve from 0.98494\n1069/1069 - 51s - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0641 - val_accuracy: 0.9844 - 51s/epoch - 48ms/step\nEpoch 44/50\n\nEpoch 44: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0679 - val_accuracy: 0.9846 - 52s/epoch - 49ms/step\nEpoch 45/50\n\nEpoch 45: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0709 - val_accuracy: 0.9837 - 52s/epoch - 49ms/step\nEpoch 46/50\n\nEpoch 46: val_accuracy did not improve from 0.98494\n1069/1069 - 51s - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0689 - val_accuracy: 0.9837 - 51s/epoch - 48ms/step\nEpoch 47/50\n\nEpoch 47: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.0733 - val_accuracy: 0.9830 - 52s/epoch - 48ms/step\nEpoch 48/50\n\nEpoch 48: val_accuracy did not improve from 0.98494\n1069/1069 - 51s - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0672 - val_accuracy: 0.9846 - 51s/epoch - 48ms/step\nEpoch 49/50\n\nEpoch 49: val_accuracy did not improve from 0.98494\n1069/1069 - 52s - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.0717 - val_accuracy: 0.9842 - 52s/epoch - 48ms/step\nEpoch 50/50\n\nEpoch 50: val_accuracy did not improve from 0.98494\n1069/1069 - 51s - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0756 - val_accuracy: 0.9835 - 51s/epoch - 48ms/step\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7be5c8af2e90>"},"metadata":{}}]},{"cell_type":"code","source":"y_predict=model.predict(X_test)\ny_predict = np.argmax(y_predict,axis=1)\naccuracy_score(y_predict,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:48:19.574389Z","iopub.execute_input":"2023-08-05T16:48:19.574823Z","iopub.status.idle":"2023-08-05T16:48:25.132391Z","shell.execute_reply.started":"2023-08-05T16:48:19.574788Z","shell.execute_reply":"2023-08-05T16:48:25.131330Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"943/943 [==============================] - 2s 2ms/step\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0.9854798607657882"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(y_predict,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:48:30.031832Z","iopub.execute_input":"2023-08-05T16:48:30.032209Z","iopub.status.idle":"2023-08-05T16:48:30.123725Z","shell.execute_reply.started":"2023-08-05T16:48:30.032176Z","shell.execute_reply":"2023-08-05T16:48:30.122585Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1090\n           1       0.98      0.99      0.99       710\n           2       0.99      0.98      0.99      1819\n           3       0.95      0.97      0.96       813\n           4       0.98      0.99      0.98       926\n           5       0.97      1.00      0.99       182\n           6       0.96      0.96      0.96       527\n           7       0.99      0.91      0.95       639\n           8       0.97      0.99      0.98       160\n           9       0.98      0.96      0.97       714\n          10       0.96      0.98      0.97       488\n          11       0.99      0.98      0.99       901\n          12       0.99      0.99      0.99      1478\n          13       0.96      1.00      0.98      1454\n          14       0.99      0.99      0.99      4383\n          15       0.99      0.99      0.99      1513\n          16       0.97      0.98      0.97       512\n          17       0.99      0.97      0.98       977\n          18       0.99      1.00      0.99      3693\n          19       0.99      0.99      0.99      1740\n          20       0.99      0.99      0.99      2256\n          21       0.98      0.98      0.98       369\n          22       0.99      0.97      0.98       907\n          23       0.97      0.99      0.98       500\n          24       0.99      0.98      0.98       875\n          25       0.99      0.99      0.99       539\n\n    accuracy                           0.99     30165\n   macro avg       0.98      0.98      0.98     30165\nweighted avg       0.99      0.99      0.99     30165\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"model_sgd.pkl\", 'zip', \"/kaggle/working/model_sgd.pkl\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:51:36.526557Z","iopub.execute_input":"2023-08-05T16:51:36.526932Z","iopub.status.idle":"2023-08-05T16:51:36.631841Z","shell.execute_reply.started":"2023-08-05T16:51:36.526901Z","shell.execute_reply":"2023-08-05T16:51:36.630769Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/model_sgd.pkl.zip'"},"metadata":{}}]},{"cell_type":"code","source":"pd.to_pickle(model,\"cnn_p.pkl\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel1=load_model(\"/kaggle/working/model_sgd.pkl\")","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:53:03.759062Z","iopub.execute_input":"2023-08-05T16:53:03.759466Z","iopub.status.idle":"2023-08-05T16:53:04.260398Z","shell.execute_reply.started":"2023-08-05T16:53:03.759427Z","shell.execute_reply":"2023-08-05T16:53:04.259323Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"y_predict=model1.predict(X_test)\ny_predict = np.argmax(y_predict,axis=1)\naccuracy_score(y_predict,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:53:18.441816Z","iopub.execute_input":"2023-08-05T16:53:18.442178Z","iopub.status.idle":"2023-08-05T16:53:21.356783Z","shell.execute_reply.started":"2023-08-05T16:53:18.442148Z","shell.execute_reply":"2023-08-05T16:53:21.355610Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"943/943 [==============================] - 2s 2ms/step\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.9866401458644124"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(y_predict,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-08-05T16:53:27.614843Z","iopub.execute_input":"2023-08-05T16:53:27.615234Z","iopub.status.idle":"2023-08-05T16:53:27.698313Z","shell.execute_reply.started":"2023-08-05T16:53:27.615198Z","shell.execute_reply":"2023-08-05T16:53:27.697114Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.99      1100\n           1       0.98      0.98      0.98       711\n           2       0.99      0.99      0.99      1807\n           3       0.94      0.96      0.95       815\n           4       0.98      0.99      0.98       928\n           5       0.98      1.00      0.99       183\n           6       0.95      0.99      0.97       505\n           7       0.97      0.98      0.98       583\n           8       0.98      0.98      0.98       163\n           9       0.97      0.98      0.98       698\n          10       0.97      0.98      0.97       493\n          11       0.99      0.98      0.98       910\n          12       1.00      0.99      0.99      1484\n          13       0.99      0.99      0.99      1507\n          14       0.99      0.99      0.99      4367\n          15       0.99      0.98      0.99      1527\n          16       0.97      0.96      0.97       521\n          17       0.99      0.98      0.98       966\n          18       1.00      0.99      1.00      3714\n          19       0.99      0.99      0.99      1750\n          20       0.99      0.99      0.99      2236\n          21       0.99      0.98      0.99       373\n          22       0.98      0.99      0.99       894\n          23       0.98      0.97      0.98       510\n          24       0.99      0.98      0.98       879\n          25       0.98      0.98      0.98       541\n\n    accuracy                           0.99     30165\n   macro avg       0.98      0.98      0.98     30165\nweighted avg       0.99      0.99      0.99     30165\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}