{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "121dc7df-994d-4193-8264-f20ec4dd4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06f705b3-6892-406d-a88d-4bff21fdbd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,sizes):\n",
    "        self.num_layers=len(sizes)\n",
    "        self.sizes=sizes\n",
    "        self.biases=[np.random.randn(y,1) for y in sizes[1:]]\n",
    "        self.weights=[np.random.randn(y,x) for x,y in zip(sizes[:-1],sizes[1:])]\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def feedforward(self,a):\n",
    "        for b,w in zip(self.biases,self.weights):\n",
    "            a=self.sigmoid(np.dot(w,a)+b)\n",
    "        return a\n",
    "    \n",
    "    def SGD(self,training_data,epochs,mini_batch_size,eta,test_data=None):\n",
    "        if test_data:\n",
    "            n_test=len(test_data[0])\n",
    "        n=len(training_data)\n",
    "        X=training_data[0]\n",
    "        Y=training_data[1]\n",
    "        for j in range(epochs):\n",
    "            mini_batches=[(X[k:k+mini_batch_size],Y[k:k+mini_batch_size]) for k in range(0,n,mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                \n",
    "                self.update_mini_batch(mini_batch,eta)\n",
    "            if test_data:\n",
    "                print(f\"Epoch {self.evaluate(test_data)} {j} / {n_test}\")\n",
    "            else:\n",
    "                print(f\"Epoch {j} complete\")\n",
    "    \n",
    "    def update_mini_batch(self,mini_batch,eta):\n",
    "        nabla_b=[np.zeros_like(b) for b in self.biases]\n",
    "        nabla_w=[np.zeros_like(w) for w in self.weights]\n",
    "        x,y=mini_batch\n",
    "        x=x.reshape(10,784,1)\n",
    "        for x,y in zip(x,y):\n",
    "            delta_nabla_b,delta_nabla_w=self.backprop(x,y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw \n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb \n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    \n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b=[np.zeros_like(b) for b in self.biases]\n",
    "        nabla_w=[np.zeros_like(w) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = self.sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * self.sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = self.sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        x,y=test_data\n",
    "        x=x.reshape(x.shape[0],784,1)\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in zip(x,y)]\n",
    "        # print(test_results)\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n",
    "\n",
    "    #### Miscellaneous functions\n",
    "\n",
    "    def sigmoid_prime(self,z):\n",
    "        \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    \n",
    "nn=Network([2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d4d0b8f5-7af5-484e-be33-a76b3b7fc472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8153/1453863329.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851 0 / 10000\n",
      "Epoch 851 1 / 10000\n",
      "Epoch 852 2 / 10000\n",
      "Epoch 852 3 / 10000\n",
      "Epoch 852 4 / 10000\n",
      "Epoch 852 5 / 10000\n",
      "Epoch 852 6 / 10000\n",
      "Epoch 851 7 / 10000\n",
      "Epoch 851 8 / 10000\n",
      "Epoch 851 9 / 10000\n",
      "Epoch 851 10 / 10000\n",
      "Epoch 851 11 / 10000\n",
      "Epoch 851 12 / 10000\n",
      "Epoch 851 13 / 10000\n",
      "Epoch 851 14 / 10000\n",
      "Epoch 851 15 / 10000\n",
      "Epoch 851 16 / 10000\n",
      "Epoch 851 17 / 10000\n",
      "Epoch 851 18 / 10000\n",
      "Epoch 851 19 / 10000\n",
      "Epoch 851 20 / 10000\n",
      "Epoch 851 21 / 10000\n",
      "Epoch 851 22 / 10000\n",
      "Epoch 851 23 / 10000\n",
      "Epoch 851 24 / 10000\n",
      "Epoch 851 25 / 10000\n",
      "Epoch 851 26 / 10000\n",
      "Epoch 851 27 / 10000\n",
      "Epoch 851 28 / 10000\n",
      "Epoch 851 29 / 10000\n"
     ]
    }
   ],
   "source": [
    "net=Network([784,30,10])\n",
    "net.SGD(training_data, 30, 10, 3, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b06b9bd-3fe8-449a-bc15-cb1062a10d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213ebc19-c251-401c-b468-d9ed8398f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data,test_data=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efc0837-767a-4384-a4c9-22194851de1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633e34c-6cc5-4a7c-99c8-2834e0dbcc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5eaf080f-557a-4110-814d-296d50ba3c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2])\n",
    "b=np.array([2,3])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4c558526-a4f6-40a7-bacc-51195b8d68df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625c724-6b79-40ee-930d-81b98ac97058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "24b371bc-9991-46bf-9b3d-2ca4c8be29ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c407f1be-236d-48fa-b8f8-e1855987c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1da4d0-98c0-491e-b6e8-f64802664a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 22:32:34.513875: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-31 22:32:34.761330: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-31 22:32:34.763566: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-31 22:32:36.478081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f596877-1936-438d-b279-88ad5bdf7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(7)\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4377536f-1aba-4f25-8b57-519af5cdaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "count,column,rows=X_train.shape\n",
    "num_pixels=column*rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3a3298-ec42-444b-86d7-82293889cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(count,num_pixels).astype(\"float32\")\n",
    "X_test=X_test.reshape(X_test.shape[0],num_pixels).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65bd1b8-eac4-4c69-91f3-2d568790b281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fab4003-f4db-4fbc-b561-fb1adf5812b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "y_train=np_utils.to_categorical(y_train)\n",
    "y_test=np_utils.to_categorical(y_test)\n",
    "num_classes=y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3c240db-843f-4bfc-be91-94b14cf45d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f296e66-590d-4aa9-9dc9-d1f787dd8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(num_pixels,activation=\"relu\"))\n",
    "    model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "    model.compile(loss=categorical_crossentropy,metrics=[\"accuracy\"],optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71bdadcf-ff8d-4090-9a18-aa7bdb26c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 22:33:07.953117: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 - 7s - loss: 0.2565 - accuracy: 0.9254 - 7s/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "400/400 - 6s - loss: 0.0984 - accuracy: 0.9708 - 6s/epoch - 15ms/step\n",
      "Epoch 3/10\n",
      "400/400 - 6s - loss: 0.0640 - accuracy: 0.9810 - 6s/epoch - 15ms/step\n",
      "Epoch 4/10\n",
      "400/400 - 6s - loss: 0.0445 - accuracy: 0.9872 - 6s/epoch - 15ms/step\n",
      "Epoch 5/10\n",
      "400/400 - 6s - loss: 0.0313 - accuracy: 0.9911 - 6s/epoch - 14ms/step\n",
      "Epoch 6/10\n",
      "400/400 - 7s - loss: 0.0221 - accuracy: 0.9939 - 7s/epoch - 17ms/step\n",
      "Epoch 7/10\n",
      "400/400 - 7s - loss: 0.0176 - accuracy: 0.9951 - 7s/epoch - 18ms/step\n",
      "Epoch 8/10\n",
      "400/400 - 6s - loss: 0.0134 - accuracy: 0.9965 - 6s/epoch - 16ms/step\n",
      "Epoch 9/10\n",
      "400/400 - 7s - loss: 0.0107 - accuracy: 0.9971 - 7s/epoch - 18ms/step\n",
      "Epoch 10/10\n",
      "400/400 - 6s - loss: 0.0084 - accuracy: 0.9978 - 6s/epoch - 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bcbfcbeb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=baseline_model()\n",
    "model.fit(X_train,y_train,epochs=10,batch_size=150,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8dc12e5-cbe4-4a66-bdf4-60ccb7eeea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (200, 784)                615440    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (200, 10)                 7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6ab6a47-b1c6-4293-a0e4-26c9c9ea813c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "110da965-64cd-4999-ad67-d2f0059b62e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ba93fba2-ae4a-42fc-92bd-8fb183aed990",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "X_train=X_train.reshape(X_train.shape[0],28,28,1).astype(\"float32\")\n",
    "X_test=X_test.reshape(X_test.shape[0],28,28,1).astype(\"float32\")\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "y_train=np_utils.to_categorical(y_train)\n",
    "y_test=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1757ea95-7260-43c2-9251-f837701d8557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "93d510e9-0691-4dfc-81c9-7c0dccbe119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model=Sequential()\n",
    "    model.add(Convolution2D(32,(5,5),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(1,1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation=\"relu\"))\n",
    "    model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "    model.compile(loss=softmax_cross_entropy_with_logits ,metrics=[\"accuracy\"],optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "59a10548-a739-46e4-b980-e896f7103b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 37s - loss: 0.1631 - accuracy: 0.9505 - 37s/epoch - 125ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 34s - loss: 0.0529 - accuracy: 0.9839 - 34s/epoch - 113ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 35s - loss: 0.0357 - accuracy: 0.9889 - 35s/epoch - 118ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 34s - loss: 0.0261 - accuracy: 0.9917 - 34s/epoch - 113ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 34s - loss: 0.0198 - accuracy: 0.9938 - 34s/epoch - 114ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 34s - loss: 0.0153 - accuracy: 0.9953 - 34s/epoch - 112ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 40s - loss: 0.0127 - accuracy: 0.9959 - 40s/epoch - 134ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 39s - loss: 0.0093 - accuracy: 0.9971 - 39s/epoch - 129ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 39s - loss: 0.0077 - accuracy: 0.9974 - 39s/epoch - 129ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 38s - loss: 0.0066 - accuracy: 0.9978 - 38s/epoch - 128ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa2f606fb0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=baseline_model()\n",
    "model.fit(X_train,y_train,epochs=10,batch_size=200,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b0d738bc-8e76-4249-942f-0e87dd4a8d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (200, 24, 24, 32)         832       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (200, 24, 24, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (200, 24, 24, 32)         0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (200, 18432)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (200, 128)                2359424   \n",
      "                                                                 \n",
      " dense_70 (Dense)            (200, 10)                 1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,361,546\n",
      "Trainable params: 2,361,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7caeb0d7-2e85-4f74-bf51-980ed73acfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D convolution layer (e.g. spatial convolution over images).\n",
      "\n",
      "    This layer creates a convolution kernel that is convolved\n",
      "    with the layer input to produce a tensor of\n",
      "    outputs. If `use_bias` is True,\n",
      "    a bias vector is created and added to the outputs. Finally, if\n",
      "    `activation` is not `None`, it is applied to the outputs as well.\n",
      "\n",
      "    When using this layer as the first layer in a model,\n",
      "    provide the keyword argument `input_shape`\n",
      "    (tuple of integers or `None`, does not include the sample axis),\n",
      "    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      "    in `data_format=\"channels_last\"`. You can use `None` when\n",
      "    a dimension has variable size.\n",
      "\n",
      "    Examples:\n",
      "\n",
      "    >>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n",
      "    >>> # size is 4.\n",
      "    >>> input_shape = (4, 28, 28, 3)\n",
      "    >>> x = tf.random.normal(input_shape)\n",
      "    >>> y = tf.keras.layers.Conv2D(\n",
      "    ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
      "    >>> print(y.shape)\n",
      "    (4, 26, 26, 2)\n",
      "\n",
      "    >>> # With `dilation_rate` as 2.\n",
      "    >>> input_shape = (4, 28, 28, 3)\n",
      "    >>> x = tf.random.normal(input_shape)\n",
      "    >>> y = tf.keras.layers.Conv2D(\n",
      "    ...     2, 3,\n",
      "    ...     activation='relu',\n",
      "    ...     dilation_rate=2,\n",
      "    ...     input_shape=input_shape[1:])(x)\n",
      "    >>> print(y.shape)\n",
      "    (4, 24, 24, 2)\n",
      "\n",
      "    >>> # With `padding` as \"same\".\n",
      "    >>> input_shape = (4, 28, 28, 3)\n",
      "    >>> x = tf.random.normal(input_shape)\n",
      "    >>> y = tf.keras.layers.Conv2D(\n",
      "    ... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
      "    >>> print(y.shape)\n",
      "    (4, 28, 28, 2)\n",
      "\n",
      "    >>> # With extended batch shape [4, 7]:\n",
      "    >>> input_shape = (4, 7, 28, 28, 3)\n",
      "    >>> x = tf.random.normal(input_shape)\n",
      "    >>> y = tf.keras.layers.Conv2D(\n",
      "    ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
      "    >>> print(y.shape)\n",
      "    (4, 7, 26, 26, 2)\n",
      "\n",
      "\n",
      "    Args:\n",
      "      filters: Integer, the dimensionality of the output space (i.e. the number\n",
      "        of output filters in the convolution).\n",
      "      kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
      "        and width of the 2D convolution window. Can be a single integer to\n",
      "        specify the same value for all spatial dimensions.\n",
      "      strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
      "        the convolution along the height and width. Can be a single integer to\n",
      "        specify the same value for all spatial dimensions. Specifying any stride\n",
      "        value != 1 is incompatible with specifying any `dilation_rate` value !=\n",
      "        1.\n",
      "      padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      "        `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n",
      "        evenly to the left/right or up/down of the input. When `padding=\"same\"`\n",
      "        and `strides=1`, the output has the same size as the input.\n",
      "      data_format: A string, one of `channels_last` (default) or\n",
      "        `channels_first`.  The ordering of the dimensions in the inputs.\n",
      "        `channels_last` corresponds to inputs with shape `(batch_size, height,\n",
      "        width, channels)` while `channels_first` corresponds to inputs with\n",
      "        shape `(batch_size, channels, height, width)`. It defaults to the\n",
      "        `image_data_format` value found in your Keras config file at\n",
      "        `~/.keras/keras.json`. If you never set it, then it will be\n",
      "        `channels_last`. Note that the `channels_first` format is currently not\n",
      "        supported by TensorFlow on CPU.\n",
      "      dilation_rate: an integer or tuple/list of 2 integers, specifying the\n",
      "        dilation rate to use for dilated convolution. Can be a single integer to\n",
      "        specify the same value for all spatial dimensions. Currently, specifying\n",
      "        any `dilation_rate` value != 1 is incompatible with specifying any\n",
      "        stride value != 1.\n",
      "      groups: A positive integer specifying the number of groups in which the\n",
      "        input is split along the channel axis. Each group is convolved\n",
      "        separately with `filters / groups` filters. The output is the\n",
      "        concatenation of all the `groups` results along the channel axis. Input\n",
      "        channels and `filters` must both be divisible by `groups`.\n",
      "      activation: Activation function to use. If you don't specify anything, no\n",
      "        activation is applied (see `keras.activations`).\n",
      "      use_bias: Boolean, whether the layer uses a bias vector.\n",
      "      kernel_initializer: Initializer for the `kernel` weights matrix (see\n",
      "        `keras.initializers`). Defaults to 'glorot_uniform'.\n",
      "      bias_initializer: Initializer for the bias vector (see\n",
      "        `keras.initializers`). Defaults to 'zeros'.\n",
      "      kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
      "        matrix (see `keras.regularizers`).\n",
      "      bias_regularizer: Regularizer function applied to the bias vector (see\n",
      "        `keras.regularizers`).\n",
      "      activity_regularizer: Regularizer function applied to the output of the\n",
      "        layer (its \"activation\") (see `keras.regularizers`).\n",
      "      kernel_constraint: Constraint function applied to the kernel matrix (see\n",
      "        `keras.constraints`).\n",
      "      bias_constraint: Constraint function applied to the bias vector (see\n",
      "        `keras.constraints`).\n",
      "\n",
      "    Input shape:\n",
      "      4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n",
      "        `data_format='channels_first'`\n",
      "      or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n",
      "        `data_format='channels_last'`.\n",
      "\n",
      "    Output shape:\n",
      "      4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n",
      "      `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n",
      "        (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n",
      "        and `cols` values might have changed due to padding.\n",
      "\n",
      "    Returns:\n",
      "      A tensor of rank 4+ representing\n",
      "      `activation(conv2d(inputs, kernel) + bias)`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: if `padding` is `\"causal\"`.\n",
      "      ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(Convolution2D.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7474eb99-0dcd-4630-a1fc-d68c25c80526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.67803035e-19],\n",
       "        [1.00681839e-18],\n",
       "        [1.00681839e-18],\n",
       "        [1.00681839e-18],\n",
       "        [7.04772688e-18],\n",
       "        [7.60707055e-18],\n",
       "        [9.78851043e-18],\n",
       "        [1.45429291e-18],\n",
       "        [9.28510238e-18],\n",
       "        [1.42632606e-17],\n",
       "        [1.38157832e-17],\n",
       "        [7.10366249e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.67803038e-18],\n",
       "        [2.01363678e-18],\n",
       "        [5.25782839e-18],\n",
       "        [8.61388998e-18],\n",
       "        [9.50883902e-18],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.25852279e-17],\n",
       "        [9.62070775e-18],\n",
       "        [1.41513877e-17],\n",
       "        [1.35361118e-17],\n",
       "        [1.09071986e-17],\n",
       "        [3.57979864e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [2.74078314e-18],\n",
       "        [1.33123743e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.40395198e-17],\n",
       "        [5.20189361e-18],\n",
       "        [4.58661641e-18],\n",
       "        [4.58661641e-18],\n",
       "        [3.13232350e-18],\n",
       "        [2.18143947e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.00681839e-18],\n",
       "        [1.22496217e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.10750005e-17],\n",
       "        [1.01800506e-17],\n",
       "        [1.38157832e-17],\n",
       "        [1.34801770e-17],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [4.47474767e-18],\n",
       "        [8.72575788e-18],\n",
       "        [5.98497516e-18],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.14665406e-17],\n",
       "        [6.15277774e-19],\n",
       "        [0.00000000e+00],\n",
       "        [2.40517694e-18],\n",
       "        [8.61388998e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [7.83080874e-19],\n",
       "        [5.59343537e-20],\n",
       "        [8.61388998e-18],\n",
       "        [1.41513877e-17],\n",
       "        [5.03409134e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [7.77487406e-18],\n",
       "        [1.41513877e-17],\n",
       "        [1.06275247e-17],\n",
       "        [1.11868707e-19],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [6.15277774e-19],\n",
       "        [1.06275247e-17],\n",
       "        [1.41513877e-17],\n",
       "        [3.91540442e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.95770221e-18],\n",
       "        [1.34801770e-17],\n",
       "        [1.25852279e-17],\n",
       "        [8.94949535e-18],\n",
       "        [6.04090994e-18],\n",
       "        [5.59343537e-20],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [4.53068204e-18],\n",
       "        [1.34242430e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [6.65618715e-18],\n",
       "        [1.39835865e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [2.51704567e-18],\n",
       "        [1.04037872e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [8.39015251e-18],\n",
       "        [1.51022748e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [8.94949659e-19],\n",
       "        [5.20189361e-18],\n",
       "        [1.40954538e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.04597220e-17],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.39276536e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.39276536e-17],\n",
       "        [3.57979864e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [2.57297962e-18],\n",
       "        [7.27146601e-18],\n",
       "        [1.02359845e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.15784085e-17],\n",
       "        [1.11868707e-19],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [2.18143947e-18],\n",
       "        [8.27828295e-18],\n",
       "        [1.28089654e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.39835875e-17],\n",
       "        [1.01800506e-17],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.34242428e-18],\n",
       "        [6.37651490e-18],\n",
       "        [1.23614896e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.12428040e-17],\n",
       "        [4.36287894e-18],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.28648981e-18],\n",
       "        [3.69166737e-18],\n",
       "        [1.19140164e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.10750005e-17],\n",
       "        [4.53068204e-18],\n",
       "        [1.11868707e-19],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [1.00681839e-18],\n",
       "        [9.56477297e-18],\n",
       "        [1.22496217e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.09071986e-17],\n",
       "        [4.47474767e-18],\n",
       "        [5.03409196e-19],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [3.07638892e-18],\n",
       "        [9.62070775e-18],\n",
       "        [1.26411619e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.36479805e-17],\n",
       "        [7.43926869e-18],\n",
       "        [6.15277774e-19],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [7.60707055e-18],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.41513877e-17],\n",
       "        [1.18580808e-17],\n",
       "        [7.55113660e-18],\n",
       "        [7.38333474e-18],\n",
       "        [8.94949659e-19],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]],\n",
       "\n",
       "       [[0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00],\n",
       "        [0.00000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8848ca-3269-4572-bf29-5453af06e459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
